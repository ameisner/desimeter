#!/usr/bin/env python
# -*- coding: utf-8 -*-

import time
filename_timestamp_format = '%Y%m%dT%H%M%S%z'
output_prefix = time.strftime(filename_timestamp_format, time.gmtime())
output_suffix = '_posparams_for_instr.csv'
output_name = output_prefix + output_suffix

__doc__ = f'''
Inspects paramfits csv table and prepares a version of the table which is
ready for operational use on the focal plane.

Output csv file will be named like "{output_name}", along with a similarly-
named text log file.

As of this writing (2020-06-12) the typical sequence is:
    
    1. get_posmoves ... get tracked (t,p) and measured (x,y) from online DB
    2. fit_posparams ... best-fit calib params which map (t,p) to (x,y)
    3. merge_posparams ... gather fit result files into one table
    4. prepare_posparams_for_instr ... THIS SCRIPT, generates modified table
    5. set_calibrations.py ... (managed in SVN) push data to the online DB
    
See DESI-5732 for data model and procedures.
'''

# command line argument parsing
import argparse
from argparse import RawTextHelpFormatter  # for making --help option respect newline characters
parser = argparse.ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)
parser.add_argument('-i', '--infile', type=str, required=True, help='path to input csv file (like "all_paramfits.csv")')
args = parser.parse_args()

# import data
from desimeter.posparams.movemask import movemask
from astropy.table import Table
input_table = Table.read(args.infile)

# import other modules
import numpy as np
import os
import logging
import desimeter.posparams.fitter as fitter

# detect "static" and "dynamic" suffixes in data headers
# generate a key mapping for which of these options to push to the output table
keys_in_to_out = {}
for header in input_table.columns:
    keys_in_to_out[header] = header
    cases = {'STATIC': fitter.static_keys,
             'DYNAMIC': fitter.dynamic_keys}
    for case, case_keys in cases.items():
        for key in case_keys:
            match_found = header.find(key) == 0 and header.find(case) != -1
            if match_found:
                keys_in_to_out[header] = key
keys_out_to_in = {val:key for key,val in keys_in_to_out.items()}
new_table = input_table.copy()
for key_in, key_out in keys_in_to_out.items():
    new_table[key_out] = new_table[key_in]

# set up a log file
script_name = os.path.basename(__file__)
out_dir = os.path.dirname(args.infile)
log_name = output_prefix + '_prepare_posparams.log'
log_path = os.path.join(out_dir, log_name)
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
[logger.removeHandler(h) for h in logger.handlers]
fh = logging.FileHandler(filename=log_path, mode='a', encoding='utf-8')
sh = logging.StreamHandler()
formatter = logging.Formatter(fmt='%(asctime)s %(levelname)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S %z')
formatter.converter = time.gmtime
fh.setFormatter(formatter)
sh.setFormatter(formatter)
logger.addHandler(fh)
logger.addHandler(sh)
logger.info(f'Running {script_name} to prepare positioner calibration parameters for use on instrument.')
logger.info(f'Input file is: {args.infile}')
logger.info(f'Table contains {len(input_table)} rows')
def input2(message):
    '''Wrapper for input which will log the interaction.'''
    logger.info(f'PROMPT: {message}')
    user_input = input('>>> ')
    if user_input == '':
        user_input = '(no entry)'
    logger.info(f'USER ENTERED >>> {user_input}')
    return user_input

# check functions

def _eliminate_rows(table, elim, rationale):
    '''Logs messages and returns a copy of table, with rows identified by elim
    deleted from it.
    
        table ... astropy table
        elim ... list of booleans saying whether to eliminate that row
                 must be same length as table
        rationale ... string message to include in log output message
    '''
    assert len(table) == len(elim), f'len(table)={len(table)} != len(elim)={len(elim)}'
    if not(any(elim)):
        return table.copy()
    elim_bool = [bool(x) for x in elim]  # guarantee a clean boolean format
    keep = [x == False for x in elim_bool]
    all_posids = set(table['POS_ID'])
    posids_remaining = set(table['POS_ID'][keep])
    posids_eliminated = all_posids - posids_remaining
    n_rows = len(table)
    n_elim_rows = len(np.argwhere(elim_bool))
    n_elim_posids = len(posids_eliminated)
    logger.warning(f'{n_elim_rows} of {n_rows} rows have {rationale}. These' +
                   f' rows will be excluded from the output table. This eliminates' +
                   f' the following {n_elim_posids} positioners from the table:' +
                   f' {sorted(posids_eliminated)}')
    output = table.copy()
    output.remove_rows(elim_bool)
    return output

def check_flags(table):
    '''Inspects FLAGS field of fit results.
    
    Internal details: Returns a copy of table.
    '''
    new = table.copy()
    for flag in movemask.names():
        fail_list = [movemask[flag] & value for value in new['FLAGS']]
        new = _eliminate_rows(new, fail_list, f'flag {flag}')
    return new

def check_static_fit_bounds(table, tighten_factor):
    '''Searches for any cases of params pegged to fitter bounds. Operates only on
    "static" parameters. Such cases immediately indicate a bad fit. Argument
    'tighten_factor' is a float which gives you some braod control to deal
    with numeric errors. It tightens the acceptable bounds by a fraction. E.g.,
    for a range [0.0, 2.0], a tighten_factor of 0.1 would use range [0.2, 1.8] in
    the filter.
    
    Internal details: Returns a copy of table.
    '''
    below_key = 'below min'
    above_key = 'above max'
    new = table.copy()
    for param in fitter.static_keys:
        minmax = fitter.default_bounds[param]
        delta = max(minmax) - min(minmax)
        limits = {below_key: min(minmax) + delta*tighten_factor,
                  above_key: max(minmax) - delta*tighten_factor}
        operators = {below_key: np.less,
                     above_key: np.greater}
        for key, limit in limits.items():
            op = operators[key]
            fail_list = op(new[param], limit)
            new = _eliminate_rows(new, fail_list, f'{param} {key} bound = {limit}')
    return new

def check_xy_offsets(table, tol):
    '''Checks reasonableness of OFFSET_X and OFFSET_Y w.r.t. metrology values.
    Argument 'tol' is a value in mm. Rows outside this tolerance will be
    eliminated from the output.
    
    Internal details: Returns a copy of table.
    '''
    return table.copy()  # not yet implemented

def check_arm_lengths(table, tol):
    '''Checks closeness of LENGTH_R1 and LENGTH_R2 to their nominal values.
    Argument 'tol' is a value in mm. Rows outside this tolerance will be
    eliminated from the output.
    
    Internal details: Returns a copy of table.
    '''
    return table.copy()  # not yet implemented

def check_fit_error(table, tol):
    '''Checks overall goodness of fit. Argument 'tol' is a value in rms um.
    Rows outside this tolerance will be eliminated from the output.
    
    Internal details: Returns a copy of table.
    '''
    return table.copy()  # not yet implemented

def check_recent_rehome(table):
    '''Searches for "recent rehome" criterion. This indicates that OFFSET_T and
    OFFSET_P are ok for use on instrument.
    
    Internal details: Returns a copy of table.'''
    # As of 2020-06-15, not implemented. The assumption is that fit_posparams
    # output file contains only good OFFSET_T, OFFSET_P, generated from an
    # assumed RECENT_REHOME==True data set. Hopefully in the future we can
    # develop a more direct check here.
    return table.copy()  # not yet implemented

def check_uniqueness(table):
    '''Searches for multiple rows with same POS_ID, and asks user to resolve
    any conflicts.
    
    Internal details: Returns a copy of table.'''
    posids = set(table['POS_ID'])
    for posid in posids:
        
    return new_table

class Check(object):
    '''Represents a check function plus arguments.
        func ... function handle
        kwargs ... keyword/args dict of inputs for that function
    '''
    def __init__(self, func, **kwargs):
        self.func = func
        self.kwargs = kwargs
    
    @property
    def name(self):
        return self.func.__name__
    
    @property
    def doc(self):
        return f'{self.name}:\n{self.func.__doc__}'
    
    def run(self, table):
        '''Performs the check function on astropy table of parameters data.'''
        args_note = f' with args {self.kwargs}' if self.kwargs else ''
        logger.info(f'{self.name}: starting{args_note}')
        output = self.func(table=table, **self.kwargs)
        n_deleted = len(table) - len(output)
        done_note = f'{self.name}: done. '
        if n_deleted:
            done_note += f'{n_deleted} rows deleted'
        else:
            done_note += f'All rows ok'
        logger.info(f'{done_note}, {len(output)} remaining')
        return output
    
    def offer_adjustment(self):
        '''Allow user to adjust check function parameters. Returns boolean
        saying whether user made an adjustment or not.'''
        if not self.kwargs:
            input2('Press enter to acknowledge')
            return False
        yesno = input2(f'Repeat {self.name} with modified args? (y/n/help)')
        if yesno == '':
            return self.offer_adjustment()
        if yesno.lower() in {'h', 'help', 'doc', 'man'}:
            logger.info(self.doc)
            return self.offer_adjustment()
        if yesno.lower() in {'n', 'no', 'false', 'f', 'o'}:
            return False
        for key, val in self.kwargs.items():
            old_kwargs = self.kwargs.copy()
            response = input2(f'Enter new {key} value (currently {val}), or blank to skip:')
            if response != '':
                self.kwargs[key] = float(response)
            was_adjusted = self.kwargs != old_kwargs
            return was_adjusted
    
    def run_and_adjust(self, table):
        '''Combines run and adjust above.'''
        user_not_done = True
        while user_not_done:
            output = self.run(table)
            was_adjusted = self.offer_adjustment()
            user_not_done = was_adjusted
        return output

# set up and run checks
checks = [Check(check_flags)]
checks += [Check(check_static_fit_bounds, tighten_factor=0.001)]
#checks += [Check(check_xy_offsets, tol=0.5)]
#checks += [Check(check_arm_lengths, tol=0.5)]
#checks += [Check(check_fit_error, tol=0.5)]
#checks += [Check(check_recent_rehome)]
checks += [Check(check_uniqueness)]
for check in checks:
    new_table = check.run_and_adjust(new_table)

# finalize which parameters to commit to DB
#  Note 1: I keep the desimeter terminology SCALE_T and SCALE_P here, for
#   consistency. Any conversion to GEAR_CALIB_T, GEAR_CALIB_P shall be performed
#   by the online upload tool (i.e. pecs/set_calibrations.py).
#  Note 2: I include PHYSICAL_RANGE_T and PHYSICAL_RANGE_P in the output table,
#   for completeness / future proofing. However, as of this writing (2020-06-16)
#   there is no specific intent to ever recalibrate them (would require work to
#   demonstrate anticollision safety).
valid_keys = ['LENGTH_R1', 'LENGTH_R2', 'OFFSET_T', 'OFFSET_P', 'OFFSET_X', 'OFFSET_Y',
              'SCALE_T', 'SCALE_P', 'PHYSICAL_RANGE_T', 'PHYSICAL_RANGE_P']
commit_prefix = 'COMMIT_'
commit_keys = {key: commit_prefix + key for key in valid_keys}

# currently unused params, included for completeness of interface
always_skip = {'PHYSICAL_RANGE_T', 'PHYSICAL_RANGE_P'}
for key in always_skip:
    if key not in new_table.columns:
        new_table[key] = None  # no data
    new_table[commit_keys[key]] = False  # do not commit

# give user specific decision over whether to commit each field
# for key, commit_key in commit_keys.items():
#     if key not in always_skip:
        
#         n_committable = 
#         yesno = input2(f'Should ')
# TO DO HERE:
#   setting <param>_COMMIT fields
#    - give user option to disable any field
#    - give user option to enable SCALES (right now, this probably takes some
#      careful human checking, positioner by positioner)

# export
import os
path = os.path.join(out_dir, output_name)
new_table.write(path)
logger.info(f'Saved output posparams to {path}.')